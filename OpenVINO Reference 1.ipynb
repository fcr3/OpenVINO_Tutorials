{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenVINO Demo\n",
    "\n",
    "## Here we will go over basic steps to use the OpenVINO\n",
    "\n",
    "Begin by loading the required packages/libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading required packages\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from openvino.inference_engine import IENetwork\n",
    "from openvino.inference_engine import IEPlugin\n",
    "import time\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# CHANGE AS NEEDED\n",
    "OS = 'linux'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we need to load in a network into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_objxml = None\n",
    "path_to_objbin = None\n",
    "\n",
    "if OS.lower() == 'linux':\n",
    "    path_to_objxml = 'wine_optimized/fp32/frozen_inference_graph.xml'\n",
    "    path_to_objbin = 'wine_optimized/fp32/frozen_inference_graph.bin'\n",
    "elif OS.lower() == 'windows':\n",
    "    path_to_objxml = 'wine_optimized\\\\fp32\\\\frozen_inference_graph.xml'\n",
    "    path_to_objbin = 'wine_optimized\\\\fp32\\\\frozen_inference_graph.bin'\n",
    "\n",
    "obj_net = IENetwork(model=path_to_objxml, weights=path_to_objbin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do some analysis of the network we have! We essentially only care about the input layers and output layers. Input layers are important because that is where we need to input our data that we receive from our environment. Output layers are important because we need to process whatever comes from there into useful data (classification, confidence, coordinates, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at the layers where the network takes inputs\n",
    "obj_net.inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at the layers where the network takes outputs\n",
    "obj_net.outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's figure out how to get those input/output layers programmatically\n",
    "input_layer = next(iter(obj_net.inputs))\n",
    "output_layer = next(iter(obj_net.outputs))\n",
    "\"Input Layer: \" + input_layer, \"Output Layer: \" + output_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's focus on the input layer, specifically its *shape*. The shape determines what kind of input that the network expects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n, c, h, w = obj_net.inputs[input_layer].shape\n",
    "n, c, h, w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on our analysis of the network, our network expects **n=1 images** with **c=3 channels** and has a **h=300 height** and a **w=300 width**. For clarification, channels refers to the RGB or Red Green Blue channels that define an image. We think of digital pictures as a collection of pixels, where each pixel has a color defined by (R, G, B). \n",
    "\n",
    "Now that we have this information, we must pre-process our input data in order to fit the requirements of the network. Let's first look at our image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_frame = cv2.imread('wine_test_images/IMG_1463.JPG')\n",
    "plt.imshow(cv2.cvtColor(obj_frame, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's preprocess our data! There is this one confusing step where we need to flip the channels from RGB to BGR. This is because when users are instructed to do model optimization, they are often told to enter the tag `--reverse_input_channels` when running configuring the model optimizer script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize image\n",
    "obj_in_frame = cv2.resize(obj_frame, (w, h))\n",
    "\n",
    "# flip channels from RBG to BGR\n",
    "obj_in_frame = obj_in_frame.transpose((2, 0, 1))\n",
    "\n",
    "# reshape data into shape network expects\n",
    "obj_in_frame = obj_in_frame.reshape((n, c, h, w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step we need to take is loading our network into an appropriate plugin. Let's say that we only have a CPU. Then in order to run these type of object detction models, we need to specify an extension for our plugin to use. This just gives our plugin extra abilities like supporting calculations on more layers than usual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ext = None\n",
    "if OS.lower() == 'windows':\n",
    "    ext = 'C:\\\\Users\\\\freyes\\\\Documents\\\\Intel\\\\OpenVINO\\\\inference_engine_samples_build\\\\intel64\\\\Release\\\\cpu_extension.dll'\n",
    "elif OS.lower() == 'linux':\n",
    "    ext = '/opt/intel/openvino/deployment_tools/inference_engine/lib/intel64/libcpu_extension_avx2.so'\n",
    "\n",
    "obj_plugin = IEPlugin(device=\"CPU\")\n",
    "obj_plugin.add_cpu_extension(ext)\n",
    "obj_exec_net = obj_plugin.load(network=obj_net, num_requests=1)\n",
    "obj_exec_net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now the moment of inference...\n",
    "\n",
    "Here we will finally be able to run inference on the data that we have! Just for our interest, we will also print the shape of the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_res = obj_exec_net.infer({input_layer: obj_in_frame})\n",
    "obj_det = obj_res[output_layer]\n",
    "obj_det.shape, obj_frame.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will post-process the data into something useful that we can hold on to. We parse the data via a for-loop. This post-processing script came from sample code that Intel provides to it's developers. The key here is that most people know what the output looks from their model. If we are novice developers, then we can reference Intel's sample code to give us some direction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_w = obj_frame.shape[1]\n",
    "initial_h = obj_frame.shape[0]\n",
    "\n",
    "labels_path = None\n",
    "if OS.lower() == 'linux':\n",
    "    labels_path = \"wine_optimized/fp16/frozen_inference_graph.labels\"\n",
    "elif OS.lower() == 'windows':\n",
    "    labels_path = \"wine_optimized\\\\fp16\\\\frozen_inference_graph.labels\"\n",
    "\n",
    "labels_map = None\n",
    "if labels_path:\n",
    "    with open(labels_path, 'r') as f:\n",
    "        labels_map = [x.strip() for x in f]\n",
    "\n",
    "for obj in obj_det[0][0]:\n",
    "    # Draw only objects when probability more than specified threshold\n",
    "    if obj[2] > 0.5:\n",
    "        xmin = int(obj[3] * initial_w)\n",
    "        ymin = int(obj[4] * initial_h)\n",
    "        xmax = int(obj[5] * initial_w)\n",
    "        ymax = int(obj[6] * initial_h)\n",
    "        class_id = int(obj[1]) - 1\n",
    "        class_string = labels_map[class_id] if labels_map else class_id\n",
    "        \n",
    "        # Let's print our classification!\n",
    "        print(\"Classification: \" + str(class_string), \"Confidence: \" + str(obj[2]))\n",
    "        \n",
    "        # Draw box and label\\class_id\n",
    "        color = (min(class_id * 12.5, 255), min(class_id * 7, 255), min(class_id * 5, 255))\n",
    "        cv2.rectangle(obj_frame, (xmin, ymin), (xmax, ymax), color, 2)\n",
    "\n",
    "plt.figure(figsize=[10,10])\n",
    "plt.imshow(cv2.cvtColor(obj_frame, cv2.COLOR_BGR2RGB)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congratuations! \n",
    "\n",
    "You now know the developer flow of OpenVINO's Python API!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
