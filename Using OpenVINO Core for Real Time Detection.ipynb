{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenVINO Demo: Real Time Detection\n",
    "\n",
    "## Let's detect objects in real time using a cam feed!\n",
    "\n",
    "Continuing on from the last demo, let's build upon what we learned and detect things in real time! We will basically redo everything we did but instead of do inference on one image, we do inference on images that come from a feed and output the drawn-on image. The thing about this process is that we can do inference super fast with Intel hardware, so it looks like we are detecting ojects in real time.\n",
    "\n",
    "From the beginning, let's create functions that will help us out later. After we import all the libraries/packages we need, let's define our first function which will pre-process our image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading required packages\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from openvino.inference_engine import IENetwork\n",
    "from openvino.inference_engine import IEPlugin\n",
    "import time\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# CHANGE THIS AS NEEDED\n",
    "OS = 'linux'\n",
    "dev = 'MYRIAD' # Change to MYRIAD if Intel NCS 2 plugged in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_processing(obj_frame, input_shape):\n",
    "    n, c, h, w = input_shape\n",
    "    obj_in_frame = cv2.resize(obj_frame, (w, h))\n",
    "    obj_in_frame = obj_in_frame.transpose((2, 0, 1))\n",
    "    obj_in_frame = obj_in_frame.reshape((n, c, h, w))\n",
    "    \n",
    "    return {\n",
    "        'blob' : obj_in_frame, \n",
    "        'frame': obj_frame, \n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now define our second function which will return our net and useful information about it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_nn(path_to_xml, path_to_bin, dev, OS):\n",
    "    obj_net = IENetwork(model=path_to_xml, weights=path_to_bin)\n",
    "    input_layer = next(iter(obj_net.inputs))\n",
    "    output_layer = next(iter(obj_net.outputs))\n",
    "    net_shape = obj_net.inputs[input_layer].shape\n",
    "    \n",
    "    ext = None\n",
    "    if OS.lower() == 'windows':\n",
    "        ext = 'C:\\\\Users\\\\freyes\\\\Documents\\\\Intel\\\\OpenVINO\\\\inference_engine_samples_build\\\\intel64\\\\Release\\\\cpu_extension.dll'\n",
    "    else:\n",
    "        ext = '/opt/intel/openvino/deployment_tools/inference_engine/lib/intel64/libcpu_extension_avx2.so'\n",
    "\n",
    "    obj_plugin = IEPlugin(device=dev)\n",
    "    if dev.lower() == 'cpu':\n",
    "        obj_plugin.add_cpu_extension(ext)\n",
    "    obj_exec_net = obj_plugin.load(network=obj_net, num_requests=1)\n",
    "    return {'net': obj_exec_net, 'input_layer': input_layer,\n",
    "            'output_layer': output_layer, 'shape': net_shape}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now define our third function which will process our data and draw the bounding box around the image we care about."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bb(obj_det, obj_frame):\n",
    "    initial_w = obj_frame.shape[1]\n",
    "    initial_h = obj_frame.shape[0]\n",
    "    green = (0, 255, 0)\n",
    "\n",
    "    for obj in obj_det[0][0]:\n",
    "        # Draw only objects when probability more than specified threshold\n",
    "        if obj[2] > 0.5:\n",
    "            xmin = int(obj[3] * initial_w)\n",
    "            ymin = int(obj[4] * initial_h)\n",
    "            xmax = int(obj[5] * initial_w)\n",
    "            ymax = int(obj[6] * initial_h)\n",
    "            class_id = int(obj[1])\n",
    "\n",
    "            # Draw box and label\\class_id\n",
    "            color = (min(class_id * 12.5, 255), min(class_id * 7, 255), min(class_id * 5, 255))\n",
    "            cv2.rectangle(obj_frame, (xmin, ymin), (xmax, ymax), color, 2)\n",
    "            cv2.putText(obj_frame, str(class_id), (xmin, ymin), cv2.FONT_HERSHEY_SIMPLEX, 0.8, green, 2, cv2.LINE_AA)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's put the pieces together!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Object Detection Section\n",
    "def main(OS, dev):\n",
    "    path_to_objxml = None\n",
    "    path_to_objbin = None\n",
    "    \n",
    "    fp = 'fp32' if dev.lower() == 'cpu' else 'fp16'\n",
    "    if OS.lower() == 'linux':\n",
    "        path_to_objxml = 'gesture_optimized/' + fp + '/frozen_inference_graph.xml'\n",
    "        path_to_objbin = 'gesture_optimized/' + fp + '/frozen_inference_graph.bin'\n",
    "    elif os.lower() == 'windows':\n",
    "        path_to_objxml = 'gesture_optimized\\\\' + fp + '\\\\frozen_inference_graph.xml'\n",
    "        path_to_objbin = 'gesture_optimized\\\\' + fp + '\\\\frozen_inference_graph.bin'\n",
    "    else:\n",
    "        print(\"Need to have either linux or windows!\")\n",
    "        return\n",
    "    \n",
    "    # net, input_layer, output_layer, shape\n",
    "    net_dict = construct_nn(path_to_objxml, path_to_objbin, dev, OS)\n",
    "    obj_exec_net = net_dict['net']\n",
    "    input_shape = net_dict['shape']\n",
    "    input_layer = net_dict['input_layer']\n",
    "    output_layer = net_dict['output_layer']\n",
    "    \n",
    "    vs = cv2.VideoCapture(0)\n",
    "    print(\"Click on the window and press q to exit the application.\")\n",
    "    while True:\n",
    "        ret, vframe = vs.read()\n",
    "        image_dict = pre_processing(vframe, input_shape)\n",
    "        inpBlob = image_dict['blob']\n",
    "        \n",
    "        # Starting timer\n",
    "        start = time.time()\n",
    "        obj_res = obj_exec_net.infer({input_layer: inpBlob})\n",
    "        \n",
    "        obj_detections = obj_res[output_layer]\n",
    "        \n",
    "        draw_bb(obj_detections, image_dict['frame'])\n",
    "        \n",
    "        # Time stamp\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        stamp = time.time() - start # in nanoseconds (10 ^ -9)\n",
    "        cv2.putText(vframe, \"Time: \" + str(stamp), (30, 30), font, 0.8, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "        cv2.putText(vframe, \"FPS: \" + str(1/stamp), (30, 60), font, 0.8, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "        cv2.imshow(\"Frame\", image_dict['frame'])\n",
    "\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord('q'):\n",
    "            break\n",
    " \n",
    "    # do a bit of cleanup\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "main(OS, dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congratulations!\n",
    "\n",
    "We now know how to detect objects in real time!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
