{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenVINO Demo: Multi-thread RT Using Core\n",
    "\n",
    "## Let's detect objects *asynchronously* in real time using a cam feed! This time, we will use the Core API.\n",
    "\n",
    "Continuing on from the last demo, let's build upon what we learned and detect things in real time and do things asynchronously with the OpenVINO Core API!\n",
    "\n",
    "From the beginning, let's create functions that will help us out later. After we import all the libraries/packages we need, let's define our first function which will pre-process our image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading required packages\n",
    "from openvino.inference_engine import IENetwork, ExecutableNetwork, IECore\n",
    "import openvino.inference_engine.ie_api\n",
    "\n",
    "import cv2\n",
    "import numpy\n",
    "import time\n",
    "import sys\n",
    "import threading\n",
    "import os\n",
    "from sys import argv\n",
    "import time\n",
    "\n",
    "# CHANGE AS NEEDED\n",
    "OS = 'windows'\n",
    "dev = 'CPU' # Change to MYRIAD if Intel NCS 2 plugged in\n",
    "User = 'fcrey' # Change to username\n",
    "\n",
    "ie = IECore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables for threading\n",
    "number_of_devices = 1\n",
    "number_of_inferences = 500\n",
    "simultaneous_infer_per_thread = 2\n",
    "threads_per_dev = 4\n",
    "images_per_thread = 4\n",
    "quit_flag = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_processing(obj_frame, input_shape):\n",
    "    n, c, h, w = input_shape\n",
    "    obj_in_frame = cv2.resize(obj_frame, (w, h))\n",
    "    obj_in_frame = obj_in_frame.transpose((2, 0, 1))\n",
    "    obj_in_frame = obj_in_frame.reshape((n, c, h, w))\n",
    "    \n",
    "    return {\n",
    "        'blob' : obj_in_frame, \n",
    "        'frame': obj_frame, \n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now define our second function which will return our net and useful information about it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_async_thread_proc(obj_exec_net: ExecutableNetwork, input_shape, vs, reqs_num, dev_thread_index, dev_num, \n",
    "                            number_of_devices, start_barrier: threading.Barrier, end_barrier: threading.Barrier, \n",
    "                            infer_result_arr: list, input_layer, output_layer):\n",
    "\n",
    "    start_barrier.wait()\n",
    "    \n",
    "    cur_request_id = reqs_num - 2\n",
    "    next_request_id = reqs_num - 1\n",
    "    requests_arr = [x for x in range(reqs_num)]\n",
    "    frame_dicts = [None for x in range(reqs_num)]\n",
    "\n",
    "    ret, pre_vframe = vs.read()\n",
    "    frame_dicts[cur_request_id] = pre_processing(pre_vframe, input_shape)\n",
    "    vframe = frame_dicts[cur_request_id]['frame']\n",
    "\n",
    "    while True:\n",
    "        start = time.time()\n",
    "        \n",
    "        # Populating frame_dictss array with next video frame dict (next_image_dict)\n",
    "        ret, next_vframe = vs.read()\n",
    "        next_image_dict = pre_processing(next_vframe, input_shape)\n",
    "        frame_dicts[next_request_id] = next_image_dict\n",
    "        \n",
    "        # Now will populate requests with next input blob, inference done in background\n",
    "        next_vframe = next_image_dict['frame']\n",
    "        next_inpBlob = next_image_dict['blob']\n",
    "        obj_res = obj_exec_net.start_async(request_id=(next_request_id+reqs_num*dev_thread_index), \n",
    "                                     inputs={input_layer: next_inpBlob})\n",
    "        \n",
    "        # Conditional will be used to process finished inference task\n",
    "        if obj_exec_net.requests[cur_request_id].wait() == 0:\n",
    "            obj_res = obj_exec_net.requests[cur_request_id].outputs\n",
    "            obj_detections = obj_res[output_layer]\n",
    "            draw_bb(obj_detections, vframe)\n",
    "        \n",
    "        # Showing current request's associated frame that was post processed\n",
    "        infer_result_arr[dev_num][reqs_num*dev_thread_index + cur_request_id] = (start, vframe)\n",
    "\n",
    "        # Switching requests and frames to focus on during next render\n",
    "        cur_request_id, next_request_id = next_request_id, (next_request_id + 1) % reqs_num\n",
    "        vframe = next_vframe\n",
    "        \n",
    "        key = cv2.waitKey(1)\n",
    "        if quit_flag == True:\n",
    "            break\n",
    "\n",
    "    # wait for all inference threads to finish\n",
    "    end_barrier.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now define our third function which will process our data and draw the bounding box around the image we care about."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bb(obj_det, obj_frame):\n",
    "    initial_w = obj_frame.shape[1]\n",
    "    initial_h = obj_frame.shape[0]\n",
    "    green = (0, 255, 0)\n",
    "\n",
    "    for obj in obj_det[0][0]:\n",
    "        # Draw only objects when probability more than specified threshold\n",
    "        if obj[2] > 0.5:\n",
    "            xmin = int(obj[3] * initial_w)\n",
    "            ymin = int(obj[4] * initial_h)\n",
    "            xmax = int(obj[5] * initial_w)\n",
    "            ymax = int(obj[6] * initial_h)\n",
    "            class_id = int(obj[1])\n",
    "\n",
    "            # Draw box and label\\class_id\n",
    "            color = (min(class_id * 12.5, 255), min(class_id * 7, 255), min(class_id * 5, 255))\n",
    "            cv2.rectangle(obj_frame, (xmin, ymin), (xmax, ymax), color, 2)\n",
    "            cv2.putText(obj_frame, str(class_id), (xmin, ymin), cv2.FONT_HERSHEY_SIMPLEX, 0.8, green, 2, cv2.LINE_AA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's put the pieces together! In this example, more variables are added to keep track of async requests and their associated video frames. Over time, frames will fill in all requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Click on the window and press q to exit the application.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-13:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\fcrey\\appdata\\local\\programs\\python\\python36\\lib\\threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\users\\fcrey\\appdata\\local\\programs\\python\\python36\\lib\\threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-4-ecd0b9fff4ab>\", line 21, in infer_async_thread_proc\n",
      "    next_image_dict = pre_processing(next_vframe, input_shape)\n",
      "  File \"<ipython-input-3-0546693b2a2f>\", line 3, in pre_processing\n",
      "    obj_in_frame = cv2.resize(obj_frame, (w, h))\n",
      "cv2.error: OpenCV(4.1.1-openvino) C:\\jenkins\\workspace\\OpenCV\\OpenVINO\\build\\opencv\\modules\\imgproc\\src\\resize.cpp:3720: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n",
      "\n",
      "\n",
      "Exception in thread Thread-11:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\fcrey\\appdata\\local\\programs\\python\\python36\\lib\\threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\users\\fcrey\\appdata\\local\\programs\\python\\python36\\lib\\threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-4-ecd0b9fff4ab>\", line 21, in infer_async_thread_proc\n",
      "    next_image_dict = pre_processing(next_vframe, input_shape)\n",
      "  File \"<ipython-input-3-0546693b2a2f>\", line 3, in pre_processing\n",
      "    obj_in_frame = cv2.resize(obj_frame, (w, h))\n",
      "cv2.error: OpenCV(4.1.1-openvino) C:\\jenkins\\workspace\\OpenCV\\OpenVINO\\build\\opencv\\modules\\imgproc\\src\\resize.cpp:3720: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-2394fdd4b38c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     93\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdestroyAllWindows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 95\u001b[1;33m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mOS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdev\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mie\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-10-2394fdd4b38c>\u001b[0m in \u001b[0;36mmain\u001b[1;34m(OS, dev, ie)\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m         \u001b[1;31m# Showing current request's associated frame that was post processed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mearliest_infer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m             \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Frame (Async Mode)\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mearliest_infer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-12:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\fcrey\\appdata\\local\\programs\\python\\python36\\lib\\threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\users\\fcrey\\appdata\\local\\programs\\python\\python36\\lib\\threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-4-ecd0b9fff4ab>\", line 21, in infer_async_thread_proc\n",
      "    next_image_dict = pre_processing(next_vframe, input_shape)\n",
      "  File \"<ipython-input-3-0546693b2a2f>\", line 3, in pre_processing\n",
      "    obj_in_frame = cv2.resize(obj_frame, (w, h))\n",
      "cv2.error: OpenCV(4.1.1-openvino) C:\\jenkins\\workspace\\OpenCV\\OpenVINO\\build\\opencv\\modules\\imgproc\\src\\resize.cpp:3720: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n",
      "\n",
      "\n",
      "Exception in thread Thread-10:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\fcrey\\appdata\\local\\programs\\python\\python36\\lib\\threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\users\\fcrey\\appdata\\local\\programs\\python\\python36\\lib\\threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-4-ecd0b9fff4ab>\", line 21, in infer_async_thread_proc\n",
      "    next_image_dict = pre_processing(next_vframe, input_shape)\n",
      "  File \"<ipython-input-3-0546693b2a2f>\", line 3, in pre_processing\n",
      "    obj_in_frame = cv2.resize(obj_frame, (w, h))\n",
      "cv2.error: OpenCV(4.1.1-openvino) C:\\jenkins\\workspace\\OpenCV\\OpenVINO\\build\\opencv\\modules\\imgproc\\src\\resize.cpp:3720: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Object Detection Section but Async!\n",
    "def main(OS, dev, ie):\n",
    "    # Variables for threading\n",
    "    inference_device = dev\n",
    "    num_ncs_devs = number_of_devices\n",
    "    total_number_threads = number_of_devices * threads_per_dev\n",
    "    \n",
    "    infer_result_arr = [[None] * (threads_per_dev * simultaneous_infer_per_thread) for x in range(number_of_devices)]\n",
    "    exec_net_list = [None] * number_of_devices\n",
    "    thread_list = [None] * (threads_per_dev * number_of_devices)\n",
    "    start_barrier = threading.Barrier(num_ncs_devs*threads_per_dev+1)\n",
    "    end_barrier = threading.Barrier(num_ncs_devs*threads_per_dev+1)\n",
    "    \n",
    "    # Setting/loading networks    \n",
    "    path_to_objxml = None\n",
    "    path_to_objbin = None\n",
    "    fp = 'fp32' if dev.lower() == 'cpu' else 'fp16'\n",
    "    if OS.lower() == 'linux':\n",
    "        path_to_objxml = 'gesture_optimized/' + fp + '/frozen_inference_graph.xml'\n",
    "        path_to_objbin = 'gesture_optimized/' + fp + '/frozen_inference_graph.bin'\n",
    "    elif OS.lower() == 'windows':\n",
    "        path_to_objxml = 'gesture_optimized\\\\' + fp + '\\\\frozen_inference_graph.xml'\n",
    "        path_to_objbin = 'gesture_optimized\\\\' + fp + '\\\\frozen_inference_graph.bin'\n",
    "    else:\n",
    "        print(\"Need to have either linux or windows!\")\n",
    "        return\n",
    "    \n",
    "    net = IENetwork(model=path_to_objxml, weights=path_to_objbin)\n",
    "    input_layer = next(iter(net.inputs))\n",
    "    output_layer = next(iter(net.outputs))\n",
    "    net_shape = net.inputs[input_layer].shape\n",
    "    \n",
    "    vs = cv2.VideoCapture(0)\n",
    "    \n",
    "    for dev_index in range(0, number_of_devices):\n",
    "        ext = None\n",
    "        if OS.lower() == 'windows':\n",
    "            ext = 'C:\\\\Users\\\\' + User + '\\\\Documents\\\\Intel\\\\OpenVINO\\\\inference_engine_samples_build\\\\intel64\\\\Release\\\\cpu_extension.dll'\n",
    "        else:\n",
    "            ext = '/opt/intel/openvino/deployment_tools/inference_engine/lib/intel64/libcpu_extension_avx2.so'\n",
    "\n",
    "        if dev.lower() == 'cpu':\n",
    "            ie.add_extension(ext, device_name=inference_device)\n",
    "        \n",
    "        exec_net_list[dev_index] = ie.load_network(network=net, \n",
    "                                                   num_requests=threads_per_dev*simultaneous_infer_per_thread, \n",
    "                                                   device_name = inference_device)\n",
    "        for dev_thread_index in range(0,threads_per_dev):\n",
    "            total_thread_index = dev_thread_index + (threads_per_dev*dev_index)\n",
    "            thread_list[total_thread_index] = threading.Thread(target=infer_async_thread_proc,\n",
    "                                                                 args=[exec_net_list[dev_index],\n",
    "                                                                       net_shape,\n",
    "                                                                       vs,\n",
    "                                                                       simultaneous_infer_per_thread,\n",
    "                                                                       dev_thread_index,\n",
    "                                                                       dev_index,\n",
    "                                                                       number_of_devices,\n",
    "                                                                       start_barrier, \n",
    "                                                                       end_barrier, \n",
    "                                                                       infer_result_arr, \n",
    "                                                                       input_layer, \n",
    "                                                                       output_layer])\n",
    "\n",
    "    del net\n",
    "    \n",
    "    #start the threads\n",
    "    for one_thread in thread_list:\n",
    "        one_thread.start()\n",
    "\n",
    "    start_barrier.wait()\n",
    "    \n",
    "    print(\"Click on the window and press q to exit the application.\")\n",
    "    while True:\n",
    "        earliest_infer = [time.time(), None]\n",
    "        for dev in range(number_of_devices):\n",
    "            for infer_index in range(threads_per_dev * simultaneous_infer_per_thread):\n",
    "                if infer_result_arr[dev][infer_index] and infer_result_arr[dev][infer_index][0] <= earliest_infer[0]:\n",
    "                    earliest_infer = infer_result_arr[dev][infer_index]\n",
    "        \n",
    "        # Showing current request's associated frame that was post processed\n",
    "        if all(earliest_infer):\n",
    "            cv2.imshow(\"Frame (Async Mode)\", earliest_infer[1])\n",
    "        \n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord('q'):\n",
    "            quit_flag = True\n",
    "            break\n",
    " \n",
    "    # do a bit of cleanup\n",
    "    # wait for threads to finish and destroy windows\n",
    "    for one_thread in thread_list:\n",
    "        one_thread.join()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "main(OS, dev, ie)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congratulations!\n",
    "\n",
    "We now know how to detect objects in real time!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
